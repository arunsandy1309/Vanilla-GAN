{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1eb38cb4",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8dcf647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd.variable import Variable\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89450a6",
   "metadata": {},
   "source": [
    "## Loading the MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e72fdacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,),(0.5,))\n",
    "                ])\n",
    "to_image = transforms.ToPILImage()\n",
    "trainset = MNIST(root='./data/', train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=100, shuffle=True)\n",
    "\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33092e02",
   "metadata": {},
   "source": [
    "## Creating the Generator & Discriminator Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2664e4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.n_features = 128\n",
    "        self.n_out = 784\n",
    "        self.fc0 = nn.Sequential(\n",
    "                    nn.Linear(self.n_features, 256),\n",
    "                    nn.LeakyReLU(0.2)\n",
    "                    )\n",
    "        self.fc1 = nn.Sequential(\n",
    "                    nn.Linear(256, 512),\n",
    "                    nn.LeakyReLU(0.2)\n",
    "                    )\n",
    "        self.fc2 = nn.Sequential(\n",
    "                    nn.Linear(512, 1024),\n",
    "                    nn.LeakyReLU(0.2)\n",
    "                    )\n",
    "        self.fc3 = nn.Sequential(\n",
    "                    nn.Linear(1024, self.n_out),\n",
    "                    nn.Tanh()\n",
    "                    )\n",
    "    def forward(self, x):\n",
    "        x = self.fc0(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = x.view(-1, 1, 28, 28)\n",
    "        return x\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.n_in = 784\n",
    "        self.n_out = 1\n",
    "        self.fc0 = nn.Sequential(\n",
    "                    nn.Linear(self.n_in, 1024),\n",
    "                    nn.LeakyReLU(0.2),\n",
    "                    nn.Dropout(0.3)\n",
    "                    )\n",
    "        self.fc1 = nn.Sequential(\n",
    "                    nn.Linear(1024, 512),\n",
    "                    nn.LeakyReLU(0.2),\n",
    "                    nn.Dropout(0.3)\n",
    "                    )\n",
    "        self.fc2 = nn.Sequential(\n",
    "                    nn.Linear(512, 256),\n",
    "                    nn.LeakyReLU(0.2),\n",
    "                    nn.Dropout(0.3)\n",
    "                    )\n",
    "        self.fc3 = nn.Sequential(\n",
    "                    nn.Linear(256, self.n_out),\n",
    "                    nn.Sigmoid()\n",
    "                    )\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = self.fc0(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45037480",
   "metadata": {},
   "source": [
    "## Creating Objects, Optimizer, BCE Loss & Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffec59c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "generator.to(device)\n",
    "discriminator.to(device)\n",
    "\n",
    "g_optim = optim.Adam(generator.parameters(), lr=2e-4)\n",
    "d_optim = optim.Adam(discriminator.parameters(), lr=2e-4)\n",
    "\n",
    "g_losses = []\n",
    "d_losses = []\n",
    "images = []\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "def noise(n, n_features=128):\n",
    "    return Variable(torch.randn(n, n_features)).to(device)\n",
    "\n",
    "def make_ones(size):\n",
    "    data = Variable(torch.ones(size, 1))\n",
    "    return data.to(device)\n",
    "\n",
    "def make_zeros(size):\n",
    "    data = Variable(torch.zeros(size, 1))\n",
    "    return data.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2a00e6",
   "metadata": {},
   "source": [
    "## Creating Functions to Train Generator and Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb9f9409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(optimizer, real_data, fake_data):\n",
    "    n = real_data.size(0)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    prediction_real = discriminator(real_data)\n",
    "    error_real = criterion(prediction_real, make_ones(n))\n",
    "    error_real.backward()\n",
    "\n",
    "    prediction_fake = discriminator(fake_data)\n",
    "    error_fake = criterion(prediction_fake, make_zeros(n))\n",
    "    \n",
    "    error_fake.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return error_real + error_fake\n",
    "\n",
    "def train_generator(optimizer, fake_data):\n",
    "    n = fake_data.size(0)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    prediction = discriminator(fake_data)\n",
    "    error = criterion(prediction, make_ones(n))\n",
    "    \n",
    "    error.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a36d4e",
   "metadata": {},
   "source": [
    "## Training the Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c498adaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0\n",
      "Epoch 0: g_loss: 1.81372511 d_loss: 0.82537574\n",
      "epoch : 1\n",
      "Epoch 1: g_loss: 1.62572193 d_loss: 0.89407593\n",
      "epoch : 2\n",
      "Epoch 2: g_loss: 1.62729192 d_loss: 0.89458758\n",
      "epoch : 3\n",
      "Epoch 3: g_loss: 1.58510482 d_loss: 0.91025281\n",
      "epoch : 4\n",
      "Epoch 4: g_loss: 1.61445010 d_loss: 0.89686686\n",
      "epoch : 5\n",
      "Epoch 5: g_loss: 1.49626625 d_loss: 0.95805651\n",
      "epoch : 6\n",
      "Epoch 6: g_loss: 1.53261042 d_loss: 0.94009465\n",
      "epoch : 7\n",
      "Epoch 7: g_loss: 1.61846125 d_loss: 0.89994645\n",
      "epoch : 8\n",
      "Epoch 8: g_loss: 1.46427107 d_loss: 0.96931857\n",
      "epoch : 9\n",
      "Epoch 9: g_loss: 1.39981699 d_loss: 0.99399817\n",
      "epoch : 10\n",
      "Epoch 10: g_loss: 1.47141731 d_loss: 0.97583044\n",
      "epoch : 11\n",
      "Epoch 11: g_loss: 1.50972044 d_loss: 0.95519459\n",
      "epoch : 12\n",
      "Epoch 12: g_loss: 1.50925016 d_loss: 0.96258694\n",
      "epoch : 13\n",
      "Epoch 13: g_loss: 1.44958758 d_loss: 0.97162688\n",
      "epoch : 14\n",
      "Epoch 14: g_loss: 1.35003328 d_loss: 1.02520931\n",
      "epoch : 15\n",
      "Epoch 15: g_loss: 1.35375488 d_loss: 1.02467811\n",
      "epoch : 16\n",
      "Epoch 16: g_loss: 1.34986687 d_loss: 1.02283359\n",
      "epoch : 17\n",
      "Epoch 17: g_loss: 1.29787338 d_loss: 1.04062951\n",
      "epoch : 18\n",
      "Epoch 18: g_loss: 1.28159511 d_loss: 1.06177461\n",
      "epoch : 19\n",
      "Epoch 19: g_loss: 1.24325049 d_loss: 1.07547343\n",
      "epoch : 20\n",
      "Epoch 20: g_loss: 1.24538505 d_loss: 1.07576048\n",
      "epoch : 21\n",
      "Epoch 21: g_loss: 1.24316728 d_loss: 1.07464826\n",
      "epoch : 22\n",
      "Epoch 22: g_loss: 1.20895922 d_loss: 1.10255039\n",
      "epoch : 23\n",
      "Epoch 23: g_loss: 1.19483781 d_loss: 1.10460532\n",
      "epoch : 24\n",
      "Epoch 24: g_loss: 1.21194124 d_loss: 1.09893644\n",
      "epoch : 25\n",
      "Epoch 25: g_loss: 1.16124153 d_loss: 1.12647152\n",
      "epoch : 26\n",
      "Epoch 26: g_loss: 1.16487455 d_loss: 1.12336695\n",
      "epoch : 27\n",
      "Epoch 27: g_loss: 1.15969443 d_loss: 1.12990713\n",
      "epoch : 28\n",
      "Epoch 28: g_loss: 1.11506546 d_loss: 1.13921535\n",
      "epoch : 29\n",
      "Epoch 29: g_loss: 1.11828458 d_loss: 1.14995682\n",
      "epoch : 30\n",
      "Epoch 30: g_loss: 1.14532208 d_loss: 1.13400185\n",
      "epoch : 31\n",
      "Epoch 31: g_loss: 1.12365198 d_loss: 1.14588761\n",
      "epoch : 32\n",
      "Epoch 32: g_loss: 1.11474431 d_loss: 1.14372849\n",
      "epoch : 33\n",
      "Epoch 33: g_loss: 1.10884964 d_loss: 1.15594912\n",
      "epoch : 34\n",
      "Epoch 34: g_loss: 1.08296144 d_loss: 1.16228724\n",
      "epoch : 35\n",
      "Epoch 35: g_loss: 1.08831453 d_loss: 1.16518044\n",
      "epoch : 36\n",
      "Epoch 36: g_loss: 1.06544173 d_loss: 1.18702245\n",
      "epoch : 37\n",
      "Epoch 37: g_loss: 1.05340409 d_loss: 1.17614734\n",
      "epoch : 38\n",
      "Epoch 38: g_loss: 1.04736137 d_loss: 1.18681717\n",
      "epoch : 39\n",
      "Epoch 39: g_loss: 1.03713560 d_loss: 1.19716036\n",
      "epoch : 40\n",
      "Epoch 40: g_loss: 1.06014895 d_loss: 1.18231857\n",
      "epoch : 41\n",
      "Epoch 41: g_loss: 1.04538298 d_loss: 1.18232286\n",
      "epoch : 42\n",
      "Epoch 42: g_loss: 1.05828655 d_loss: 1.18022144\n",
      "epoch : 43\n",
      "Epoch 43: g_loss: 1.04023647 d_loss: 1.19236124\n",
      "epoch : 44\n",
      "Epoch 44: g_loss: 1.02548623 d_loss: 1.20206010\n",
      "epoch : 45\n",
      "Epoch 45: g_loss: 1.01611018 d_loss: 1.20953488\n",
      "epoch : 46\n",
      "Epoch 46: g_loss: 0.99176675 d_loss: 1.21594536\n",
      "epoch : 47\n",
      "Epoch 47: g_loss: 0.99702424 d_loss: 1.21437955\n",
      "epoch : 48\n",
      "Epoch 48: g_loss: 0.99444437 d_loss: 1.22258532\n",
      "epoch : 49\n",
      "Epoch 49: g_loss: 1.00088775 d_loss: 1.21289325\n",
      "epoch : 50\n",
      "Epoch 50: g_loss: 0.99809086 d_loss: 1.21438205\n",
      "epoch : 51\n",
      "Epoch 51: g_loss: 1.01279998 d_loss: 1.20773280\n",
      "epoch : 52\n",
      "Epoch 52: g_loss: 0.99005795 d_loss: 1.22638655\n",
      "epoch : 53\n",
      "Epoch 53: g_loss: 0.98458612 d_loss: 1.22643960\n",
      "epoch : 54\n",
      "Epoch 54: g_loss: 0.97238141 d_loss: 1.23034024\n",
      "epoch : 55\n",
      "Epoch 55: g_loss: 0.98434758 d_loss: 1.22269619\n",
      "epoch : 56\n",
      "Epoch 56: g_loss: 0.96237952 d_loss: 1.24070632\n",
      "epoch : 57\n",
      "Epoch 57: g_loss: 0.97207063 d_loss: 1.23216522\n",
      "epoch : 58\n",
      "Epoch 58: g_loss: 0.96912861 d_loss: 1.23037410\n",
      "epoch : 59\n",
      "Epoch 59: g_loss: 0.95069081 d_loss: 1.24164176\n",
      "epoch : 60\n",
      "Epoch 60: g_loss: 0.96904606 d_loss: 1.24325466\n",
      "epoch : 61\n",
      "Epoch 61: g_loss: 0.97257662 d_loss: 1.23026824\n",
      "epoch : 62\n",
      "Epoch 62: g_loss: 0.97075403 d_loss: 1.23570836\n",
      "epoch : 63\n",
      "Epoch 63: g_loss: 0.96764880 d_loss: 1.23059309\n",
      "epoch : 64\n",
      "Epoch 64: g_loss: 0.95378423 d_loss: 1.24708307\n",
      "epoch : 65\n",
      "Epoch 65: g_loss: 0.94519204 d_loss: 1.24553609\n",
      "epoch : 66\n",
      "Epoch 66: g_loss: 0.97238845 d_loss: 1.24444211\n",
      "epoch : 67\n",
      "Epoch 67: g_loss: 0.95845002 d_loss: 1.23951125\n",
      "epoch : 68\n",
      "Epoch 68: g_loss: 0.94346869 d_loss: 1.25331628\n",
      "epoch : 69\n",
      "Epoch 69: g_loss: 0.94503808 d_loss: 1.25244367\n",
      "epoch : 70\n",
      "Epoch 70: g_loss: 0.92480475 d_loss: 1.25968862\n",
      "epoch : 71\n",
      "Epoch 71: g_loss: 0.93175268 d_loss: 1.25526738\n",
      "epoch : 72\n",
      "Epoch 72: g_loss: 0.94457090 d_loss: 1.25575376\n",
      "epoch : 73\n",
      "Epoch 73: g_loss: 0.92228889 d_loss: 1.26180172\n",
      "epoch : 74\n",
      "Epoch 74: g_loss: 0.92541552 d_loss: 1.25921321\n",
      "epoch : 75\n",
      "Epoch 75: g_loss: 0.92635185 d_loss: 1.26246202\n",
      "epoch : 76\n",
      "Epoch 76: g_loss: 0.92227429 d_loss: 1.25713551\n",
      "epoch : 77\n",
      "Epoch 77: g_loss: 0.93155289 d_loss: 1.25555277\n",
      "epoch : 78\n",
      "Epoch 78: g_loss: 0.92311716 d_loss: 1.26738763\n",
      "epoch : 79\n",
      "Epoch 79: g_loss: 0.93562478 d_loss: 1.25503993\n",
      "epoch : 80\n",
      "Epoch 80: g_loss: 0.92975104 d_loss: 1.26256859\n",
      "epoch : 81\n",
      "Epoch 81: g_loss: 0.93462318 d_loss: 1.25240004\n",
      "epoch : 82\n",
      "Epoch 82: g_loss: 0.93279660 d_loss: 1.25963020\n",
      "epoch : 83\n",
      "Epoch 83: g_loss: 0.92806202 d_loss: 1.25946295\n",
      "epoch : 84\n",
      "Epoch 84: g_loss: 0.91269618 d_loss: 1.26747477\n",
      "epoch : 85\n",
      "Epoch 85: g_loss: 0.92702311 d_loss: 1.26010108\n",
      "epoch : 86\n",
      "Epoch 86: g_loss: 0.92169052 d_loss: 1.26008070\n",
      "epoch : 87\n",
      "Epoch 87: g_loss: 0.92641020 d_loss: 1.26327884\n",
      "epoch : 88\n",
      "Epoch 88: g_loss: 0.92148888 d_loss: 1.26256061\n",
      "epoch : 89\n",
      "Epoch 89: g_loss: 0.91049433 d_loss: 1.27193630\n",
      "epoch : 90\n",
      "Epoch 90: g_loss: 0.90836543 d_loss: 1.27045047\n",
      "epoch : 91\n",
      "Epoch 91: g_loss: 0.90773010 d_loss: 1.26673973\n",
      "epoch : 92\n",
      "Epoch 92: g_loss: 0.91531467 d_loss: 1.26628160\n",
      "epoch : 93\n",
      "Epoch 93: g_loss: 0.90787804 d_loss: 1.27781677\n",
      "epoch : 94\n",
      "Epoch 94: g_loss: 0.91557920 d_loss: 1.27067292\n",
      "epoch : 95\n",
      "Epoch 95: g_loss: 0.91314918 d_loss: 1.26966178\n",
      "epoch : 96\n",
      "Epoch 96: g_loss: 0.91662914 d_loss: 1.26665211\n",
      "epoch : 97\n",
      "Epoch 97: g_loss: 0.89364481 d_loss: 1.27768993\n",
      "epoch : 98\n",
      "Epoch 98: g_loss: 0.90170503 d_loss: 1.27760231\n",
      "epoch : 99\n",
      "Epoch 99: g_loss: 0.91534108 d_loss: 1.26820302\n",
      "epoch : 100\n",
      "Epoch 100: g_loss: 0.90584677 d_loss: 1.27770090\n",
      "epoch : 101\n",
      "Epoch 101: g_loss: 0.90826005 d_loss: 1.26733029\n",
      "epoch : 102\n",
      "Epoch 102: g_loss: 0.90246356 d_loss: 1.27198815\n",
      "epoch : 103\n",
      "Epoch 103: g_loss: 0.90183538 d_loss: 1.27370179\n",
      "epoch : 104\n",
      "Epoch 104: g_loss: 0.91068697 d_loss: 1.27223551\n",
      "epoch : 105\n",
      "Epoch 105: g_loss: 0.90035188 d_loss: 1.27653778\n",
      "epoch : 106\n",
      "Epoch 106: g_loss: 0.89951050 d_loss: 1.27790010\n",
      "epoch : 107\n",
      "Epoch 107: g_loss: 0.89850861 d_loss: 1.27653742\n",
      "epoch : 108\n",
      "Epoch 108: g_loss: 0.91177535 d_loss: 1.27071130\n",
      "epoch : 109\n",
      "Epoch 109: g_loss: 0.90743583 d_loss: 1.26963890\n",
      "epoch : 110\n",
      "Epoch 110: g_loss: 0.89139277 d_loss: 1.27523851\n",
      "epoch : 111\n",
      "Epoch 111: g_loss: 0.89491230 d_loss: 1.27813935\n",
      "epoch : 112\n",
      "Epoch 112: g_loss: 0.91207421 d_loss: 1.27304411\n",
      "epoch : 113\n",
      "Epoch 113: g_loss: 0.90079796 d_loss: 1.27821326\n",
      "epoch : 114\n",
      "Epoch 114: g_loss: 0.89710987 d_loss: 1.27926087\n",
      "epoch : 115\n",
      "Epoch 115: g_loss: 0.87986374 d_loss: 1.28858078\n",
      "epoch : 116\n",
      "Epoch 116: g_loss: 0.89613497 d_loss: 1.27652860\n",
      "epoch : 117\n",
      "Epoch 117: g_loss: 0.89256334 d_loss: 1.27828801\n",
      "epoch : 118\n",
      "Epoch 118: g_loss: 0.91710341 d_loss: 1.26840413\n",
      "epoch : 119\n",
      "Epoch 119: g_loss: 0.87887543 d_loss: 1.28387010\n",
      "epoch : 120\n",
      "Epoch 120: g_loss: 0.88472748 d_loss: 1.28499031\n",
      "epoch : 121\n",
      "Epoch 121: g_loss: 0.89665085 d_loss: 1.27904475\n",
      "epoch : 122\n",
      "Epoch 122: g_loss: 0.88700342 d_loss: 1.28168118\n",
      "epoch : 123\n",
      "Epoch 123: g_loss: 0.89722157 d_loss: 1.28105259\n",
      "epoch : 124\n",
      "Epoch 124: g_loss: 0.88982069 d_loss: 1.28210914\n",
      "epoch : 125\n",
      "Epoch 125: g_loss: 0.87995178 d_loss: 1.28692234\n",
      "epoch : 126\n",
      "Epoch 126: g_loss: 0.88654202 d_loss: 1.28652716\n",
      "epoch : 127\n",
      "Epoch 127: g_loss: 0.88857126 d_loss: 1.28222585\n",
      "epoch : 128\n",
      "Epoch 128: g_loss: 0.89745623 d_loss: 1.27860868\n",
      "epoch : 129\n",
      "Epoch 129: g_loss: 0.88693351 d_loss: 1.28589058\n",
      "epoch : 130\n",
      "Epoch 130: g_loss: 0.90333331 d_loss: 1.27823937\n",
      "epoch : 131\n",
      "Epoch 131: g_loss: 0.88650829 d_loss: 1.28252649\n",
      "epoch : 132\n",
      "Epoch 132: g_loss: 0.87841314 d_loss: 1.28753746\n",
      "epoch : 133\n",
      "Epoch 133: g_loss: 0.89010519 d_loss: 1.28136182\n",
      "epoch : 134\n",
      "Epoch 134: g_loss: 0.88934058 d_loss: 1.27959478\n",
      "epoch : 135\n",
      "Epoch 135: g_loss: 0.88199133 d_loss: 1.28727305\n",
      "epoch : 136\n",
      "Epoch 136: g_loss: 0.88131809 d_loss: 1.28172708\n",
      "epoch : 137\n",
      "Epoch 137: g_loss: 0.87734610 d_loss: 1.28791511\n",
      "epoch : 138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138: g_loss: 0.88277233 d_loss: 1.28530073\n",
      "epoch : 139\n",
      "Epoch 139: g_loss: 0.87827438 d_loss: 1.28813374\n",
      "epoch : 140\n",
      "Epoch 140: g_loss: 0.88712174 d_loss: 1.28225029\n",
      "epoch : 141\n",
      "Epoch 141: g_loss: 0.88274938 d_loss: 1.28116226\n",
      "epoch : 142\n",
      "Epoch 142: g_loss: 0.88291293 d_loss: 1.28964508\n",
      "epoch : 143\n",
      "Epoch 143: g_loss: 0.87464017 d_loss: 1.28876066\n",
      "epoch : 144\n",
      "Epoch 144: g_loss: 0.86869216 d_loss: 1.29263985\n",
      "epoch : 145\n",
      "Epoch 145: g_loss: 0.87818778 d_loss: 1.28494143\n",
      "epoch : 146\n",
      "Epoch 146: g_loss: 0.88480002 d_loss: 1.28607011\n",
      "epoch : 147\n",
      "Epoch 147: g_loss: 0.88023472 d_loss: 1.29062140\n",
      "epoch : 148\n",
      "Epoch 148: g_loss: 0.88072199 d_loss: 1.28811395\n",
      "epoch : 149\n",
      "Epoch 149: g_loss: 0.88218266 d_loss: 1.28882337\n",
      "epoch : 150\n",
      "Epoch 150: g_loss: 0.87344891 d_loss: 1.29368985\n",
      "epoch : 151\n",
      "Epoch 151: g_loss: 0.87263119 d_loss: 1.29173255\n",
      "epoch : 152\n",
      "Epoch 152: g_loss: 0.88275421 d_loss: 1.28550565\n",
      "epoch : 153\n",
      "Epoch 153: g_loss: 0.87430954 d_loss: 1.28538072\n",
      "epoch : 154\n",
      "Epoch 154: g_loss: 0.87859368 d_loss: 1.28911960\n",
      "epoch : 155\n",
      "Epoch 155: g_loss: 0.87079000 d_loss: 1.28912997\n",
      "epoch : 156\n",
      "Epoch 156: g_loss: 0.87408322 d_loss: 1.29014313\n",
      "epoch : 157\n",
      "Epoch 157: g_loss: 0.87440979 d_loss: 1.28764474\n",
      "epoch : 158\n",
      "Epoch 158: g_loss: 0.87796074 d_loss: 1.28964913\n",
      "epoch : 159\n",
      "Epoch 159: g_loss: 0.87467951 d_loss: 1.28716719\n",
      "epoch : 160\n",
      "Epoch 160: g_loss: 0.86872560 d_loss: 1.29180288\n",
      "epoch : 161\n",
      "Epoch 161: g_loss: 0.87611157 d_loss: 1.29105949\n",
      "epoch : 162\n",
      "Epoch 162: g_loss: 0.86517656 d_loss: 1.29202998\n",
      "epoch : 163\n",
      "Epoch 163: g_loss: 0.87232780 d_loss: 1.28947663\n",
      "epoch : 164\n",
      "Epoch 164: g_loss: 0.87566966 d_loss: 1.29258287\n",
      "epoch : 165\n",
      "Epoch 165: g_loss: 0.86061901 d_loss: 1.29312611\n",
      "epoch : 166\n",
      "Epoch 166: g_loss: 0.87620497 d_loss: 1.29424429\n",
      "epoch : 167\n",
      "Epoch 167: g_loss: 0.87119073 d_loss: 1.29084945\n",
      "epoch : 168\n",
      "Epoch 168: g_loss: 0.87216890 d_loss: 1.28923965\n",
      "epoch : 169\n",
      "Epoch 169: g_loss: 0.87301129 d_loss: 1.29076040\n",
      "epoch : 170\n",
      "Epoch 170: g_loss: 0.88697970 d_loss: 1.28874826\n",
      "epoch : 171\n",
      "Epoch 171: g_loss: 0.88234210 d_loss: 1.28532982\n",
      "epoch : 172\n",
      "Epoch 172: g_loss: 0.87436444 d_loss: 1.29126179\n",
      "epoch : 173\n",
      "Epoch 173: g_loss: 0.87450790 d_loss: 1.29807448\n",
      "epoch : 174\n",
      "Epoch 174: g_loss: 0.87596309 d_loss: 1.29087591\n",
      "epoch : 175\n",
      "Epoch 175: g_loss: 0.87090749 d_loss: 1.29383731\n",
      "epoch : 176\n",
      "Epoch 176: g_loss: 0.87262768 d_loss: 1.29037368\n",
      "epoch : 177\n",
      "Epoch 177: g_loss: 0.87068981 d_loss: 1.29102552\n",
      "epoch : 178\n",
      "Epoch 178: g_loss: 0.86535907 d_loss: 1.29610074\n",
      "epoch : 179\n",
      "Epoch 179: g_loss: 0.87496167 d_loss: 1.29302561\n",
      "epoch : 180\n",
      "Epoch 180: g_loss: 0.86596859 d_loss: 1.29485786\n",
      "epoch : 181\n",
      "Epoch 181: g_loss: 0.86411524 d_loss: 1.29283869\n",
      "epoch : 182\n",
      "Epoch 182: g_loss: 0.85195065 d_loss: 1.29963696\n",
      "epoch : 183\n",
      "Epoch 183: g_loss: 0.87970150 d_loss: 1.29525399\n",
      "epoch : 184\n",
      "Epoch 184: g_loss: 0.86873269 d_loss: 1.29312527\n",
      "epoch : 185\n",
      "Epoch 185: g_loss: 0.86775392 d_loss: 1.29546332\n",
      "epoch : 186\n",
      "Epoch 186: g_loss: 0.86043471 d_loss: 1.30101466\n",
      "epoch : 187\n",
      "Epoch 187: g_loss: 0.86564976 d_loss: 1.29778886\n",
      "epoch : 188\n",
      "Epoch 188: g_loss: 0.87298805 d_loss: 1.29206061\n",
      "epoch : 189\n",
      "Epoch 189: g_loss: 0.85780209 d_loss: 1.29882157\n",
      "epoch : 190\n",
      "Epoch 190: g_loss: 0.87135929 d_loss: 1.29021382\n",
      "epoch : 191\n",
      "Epoch 191: g_loss: 0.86855847 d_loss: 1.29253316\n",
      "epoch : 192\n",
      "Epoch 192: g_loss: 0.86373752 d_loss: 1.29646337\n",
      "epoch : 193\n",
      "Epoch 193: g_loss: 0.85811770 d_loss: 1.29780245\n",
      "epoch : 194\n",
      "Epoch 194: g_loss: 0.85843813 d_loss: 1.30026102\n",
      "epoch : 195\n",
      "Epoch 195: g_loss: 0.86624283 d_loss: 1.29462957\n",
      "epoch : 196\n",
      "Epoch 196: g_loss: 0.88212562 d_loss: 1.29114366\n",
      "epoch : 197\n",
      "Epoch 197: g_loss: 0.86664772 d_loss: 1.29319823\n",
      "epoch : 198\n",
      "Epoch 198: g_loss: 0.86612970 d_loss: 1.29549336\n",
      "epoch : 199\n",
      "Epoch 199: g_loss: 0.86767656 d_loss: 1.29981947\n",
      "epoch : 200\n",
      "Epoch 200: g_loss: 0.86768949 d_loss: 1.29793513\n",
      "epoch : 201\n",
      "Epoch 201: g_loss: 0.86814171 d_loss: 1.29151058\n",
      "epoch : 202\n",
      "Epoch 202: g_loss: 0.86317676 d_loss: 1.29643321\n",
      "epoch : 203\n",
      "Epoch 203: g_loss: 0.85577369 d_loss: 1.29610133\n",
      "epoch : 204\n",
      "Epoch 204: g_loss: 0.86811596 d_loss: 1.29665887\n",
      "epoch : 205\n",
      "Epoch 205: g_loss: 0.86806488 d_loss: 1.29176843\n",
      "epoch : 206\n",
      "Epoch 206: g_loss: 0.86844432 d_loss: 1.29581368\n",
      "epoch : 207\n",
      "Epoch 207: g_loss: 0.86964661 d_loss: 1.29388392\n",
      "epoch : 208\n",
      "Epoch 208: g_loss: 0.87647277 d_loss: 1.29450727\n",
      "epoch : 209\n",
      "Epoch 209: g_loss: 0.86152875 d_loss: 1.29469454\n",
      "epoch : 210\n",
      "Epoch 210: g_loss: 0.85642123 d_loss: 1.30015981\n",
      "epoch : 211\n",
      "Epoch 211: g_loss: 0.86893660 d_loss: 1.29681611\n",
      "epoch : 212\n",
      "Epoch 212: g_loss: 0.86162210 d_loss: 1.29731488\n",
      "epoch : 213\n",
      "Epoch 213: g_loss: 0.85939300 d_loss: 1.30158246\n",
      "epoch : 214\n",
      "Epoch 214: g_loss: 0.86075300 d_loss: 1.29981077\n",
      "epoch : 215\n",
      "Epoch 215: g_loss: 0.86953735 d_loss: 1.29405463\n",
      "epoch : 216\n",
      "Epoch 216: g_loss: 0.86578512 d_loss: 1.29631615\n",
      "epoch : 217\n",
      "Epoch 217: g_loss: 0.86677295 d_loss: 1.29446518\n",
      "epoch : 218\n",
      "Epoch 218: g_loss: 0.85641938 d_loss: 1.29708266\n",
      "epoch : 219\n",
      "Epoch 219: g_loss: 0.86715955 d_loss: 1.29738295\n",
      "epoch : 220\n",
      "Epoch 220: g_loss: 0.85986662 d_loss: 1.29642165\n",
      "epoch : 221\n",
      "Epoch 221: g_loss: 0.86725330 d_loss: 1.29554367\n",
      "epoch : 222\n",
      "Epoch 222: g_loss: 0.87173706 d_loss: 1.29329526\n",
      "epoch : 223\n",
      "Epoch 223: g_loss: 0.85903972 d_loss: 1.30387294\n",
      "epoch : 224\n",
      "Epoch 224: g_loss: 0.87723970 d_loss: 1.29278970\n",
      "epoch : 225\n",
      "Epoch 225: g_loss: 0.87730688 d_loss: 1.28950775\n",
      "epoch : 226\n",
      "Epoch 226: g_loss: 0.86250246 d_loss: 1.29330027\n",
      "epoch : 227\n",
      "Epoch 227: g_loss: 0.86925340 d_loss: 1.29713225\n",
      "epoch : 228\n",
      "Epoch 228: g_loss: 0.87345862 d_loss: 1.28849578\n",
      "epoch : 229\n",
      "Epoch 229: g_loss: 0.86979377 d_loss: 1.29435778\n",
      "epoch : 230\n",
      "Epoch 230: g_loss: 0.86712217 d_loss: 1.29713249\n",
      "epoch : 231\n",
      "Epoch 231: g_loss: 0.85899967 d_loss: 1.30003798\n",
      "epoch : 232\n",
      "Epoch 232: g_loss: 0.86921948 d_loss: 1.29501617\n",
      "epoch : 233\n",
      "Epoch 233: g_loss: 0.85924131 d_loss: 1.29864216\n",
      "epoch : 234\n",
      "Epoch 234: g_loss: 0.87018055 d_loss: 1.29472208\n",
      "epoch : 235\n",
      "Epoch 235: g_loss: 0.86592317 d_loss: 1.29227257\n",
      "epoch : 236\n",
      "Epoch 236: g_loss: 0.85755837 d_loss: 1.29671073\n",
      "epoch : 237\n",
      "Epoch 237: g_loss: 0.87414199 d_loss: 1.29050148\n",
      "epoch : 238\n",
      "Epoch 238: g_loss: 0.86959231 d_loss: 1.29556906\n",
      "epoch : 239\n",
      "Epoch 239: g_loss: 0.86979556 d_loss: 1.29178226\n",
      "epoch : 240\n",
      "Epoch 240: g_loss: 0.86089492 d_loss: 1.29763854\n",
      "epoch : 241\n",
      "Epoch 241: g_loss: 0.87267268 d_loss: 1.29182649\n",
      "epoch : 242\n",
      "Epoch 242: g_loss: 0.86678916 d_loss: 1.29434896\n",
      "epoch : 243\n",
      "Epoch 243: g_loss: 0.86350572 d_loss: 1.29821992\n",
      "epoch : 244\n",
      "Epoch 244: g_loss: 0.86983359 d_loss: 1.29326713\n",
      "epoch : 245\n",
      "Epoch 245: g_loss: 0.87076014 d_loss: 1.29177439\n",
      "epoch : 246\n",
      "Epoch 246: g_loss: 0.87377501 d_loss: 1.29225445\n",
      "epoch : 247\n",
      "Epoch 247: g_loss: 0.87734663 d_loss: 1.28787982\n",
      "epoch : 248\n",
      "Epoch 248: g_loss: 0.86379874 d_loss: 1.29456723\n",
      "epoch : 249\n",
      "Epoch 249: g_loss: 0.88258767 d_loss: 1.28994370\n",
      "Training Finished\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 250\n",
    "k = 1\n",
    "test_noise = noise(64)\n",
    "\n",
    "generator.train()\n",
    "discriminator.train()\n",
    "for epoch in range(num_epochs):\n",
    "    g_error = 0.0\n",
    "    d_error = 0.0\n",
    "    print('epoch :',epoch)\n",
    "    for i, data in enumerate(trainloader):\n",
    "        imgs, _ = data\n",
    "        n = len(imgs)\n",
    "        for j in range(k):\n",
    "            fake_data = generator(noise(n)).detach()\n",
    "            real_data = imgs.to(device)\n",
    "            d_error += train_discriminator(d_optim, real_data, fake_data)\n",
    "        fake_data = generator(noise(n))\n",
    "        g_error += train_generator(g_optim, fake_data)\n",
    "    img = generator(test_noise).cpu().detach()\n",
    "    img = make_grid(img)\n",
    "    images.append(img)\n",
    "    g_losses.append(g_error/i)\n",
    "    d_losses.append(d_error/i)\n",
    "    print('Epoch {}: g_loss: {:.8f} d_loss: {:.8f}\\r'.format(epoch, g_error/i, d_error/i))\n",
    "    \n",
    "print('Training Finished')\n",
    "torch.save(generator.state_dict(), 'mnist_generator.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a9d6b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "imgs = [np.array(to_image(i)) for i in images]\n",
    "imageio.mimsave('progress.gif', imgs)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
